\TODO
How it was to implement a CA system inside an FPGA.
Distributed and local communication allows it to fills entire FPGA.
Perfect for 2D structure, extra routing challenges with 3D.


\TODO
Many resources left.
Scaling restricted by routing; almost all paths are critical.
CA shift registers are spread over whole FPGA.
It is summed into one bram (livecount).
Then spread all over, since DFT uses nearly all DSP slices.

%==============================================================================%

\section{Resource Usage}

With a complete rewrite, it is interesting to see the differences in resource usage between equivalent setups.
Due to architectural differences, the performance of the new design can not be perfectly matched with that of the previous, but it should be close enough to determine the general trend.

The most closely matching configuration is:
[LUT Configuration Bits] maximized to 2 in 2D and 8 in 3D,
[Rules Tested In Parallel] set to 2,
[Type Bits] set to 5,
[State Bits] set to 1,
[Fitness] set to Live Count
and buffer sizes set to 256.
Other parameters do not significantly influence resource usage, functionality or performance.

In 3D, the live counter is four times faster, configuration is half as fast, and readback is an eight as fast.
In 2D, configuation is a quarter as fast for 32x32 matrices.
Due to different scaling in the old 2D design, no other matrix sizes have equivalent performance and have therefore been left out of the comparison.
The results are presented in \tablename~\ref{tab:resource-usage}.

\begin{table}[!ht]
    \renewcommand{\arraystretch}{1.4}
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c|c}
        \bfseries Matrix & \multicolumn{2}{c|}{\bfseries SRL16} & \multicolumn{2}{c|}{\bfseries LUTs} & \multicolumn{2}{c|}{\bfseries Registers} & \multicolumn{2}{c}{\bfseries BRAMs} \\
        \bfseries (XxYxZ) & \bfseries Total & \bfseries \% & \bfseries Old & \bfseries New & \bfseries Old & \bfseries New & \bfseries Old & \bfseries New \\
        \hline
        32x32 & 2048 & 32.0 & 14858 & 11277 & 16259 & 7043 & 38 & 53 \\
        8x8x4 & 2048 & 32.0 & 6529 & 6265 & 6011 & 4495 & 55 & 47 \\
        8x8x8 & 4096 & 63.9 & 7668 & 8374 & 5726 & 4913 & 50 & 47 \\
        8x16x4 & 4096 & 63.9 & 8234 & 8252 & 6531 & 4957 & 50 & 47 \\
        10x10x8 & 6400 & 99.9 & – & 11313 & – & 5832 & – & 52 \\
    \end{tabular}
    \caption[Resource usage]{
        Resource usage without DFT compared to the old design with most equivalently configured setup and performance.
        The old numbers are from \cite{stovneng2014sblock}.
    }
    \label{tab:resource-usage}
\end{table}

The new design appears to be slightly more efficient in 3D.
It uses about the same amount of LUTs, but substantially fewer registers and slightly fewer BRAMs.
This is a bit surprising considering the four times larger adder tree.
In 2D, both LUT and register usage are drastically reduced.

The size of the matrix is limited by the number of available 16-bit shift registers (SRL16s), as each sblock uses 2 in 2D and 8 in 3D.
Since the new design is more finely tunable, larger matrices can be fitted onto the chip.
A 10x10x8 matrix design uses 99.9\% of the 6408 shift registers on the Spartan-6 LX45T, and has been successfully implemented and tested with the above configuration.
It will even implement with [Rules Tested In Parallel] increased to 6 and [Fitness] set to DFT.
At this point, routing becomes the main problem, as there are still many logic resources left.

%==============================================================================%

\section{Performance}

Previous hardware designs have been profiled by the test program in \figurename~\ref{fig:test-program}, with an 8x8 matrix and 6 development rules.
It is mainly a stress-test of the CA stepping speed.
The best speeds were 6.3 seconds in both \cite{djupdal2003sblock} and \cite{stovneng2014sblock}.

\begin{figure}[!ht]
\begin{lstlisting}[xleftmargin=0.34\textwidth]
initialize()
while counter[0] != 10000:
    config()
    step(50000)
    readback()
    swap_cell_storage()
    read_types()
    read_states()
    develop()
    counter[0]++
\end{lstlisting}
\caption[Test program] {
    Updated test program from \cite{djupdal2003sblock}.
}
\label{fig:test-program}
\end{figure}

On the new platform, the program completes in 8.2 seconds.
This is exactly twice of what it should take at 125 MHz.
Further study show that the PCI Express Endpoint Block is to blame as it actually halves the frequency to 62.5 MHz at the user side.
This fact is barely mentioned once in \cite{ug672} and is never referred to by the IP core generator or example design.
It has also gone unnoticed in simulations since the communication module has been replaced with a special simulation version.
Still, running at half speed, the platform is only about 30\% slower than the previous design for this test.
During synthesis and implementation, the constraint of 125 MHz appears to have been applied to all signals though, which means that is possible to (again) separate the communication module into a slower clock domain and thus double the speed of the remaining design.
This would make it 35\% faster than the previous design instead.


\TODO

As with the previous 3D design, the performance of certain modules scale with the matrix width (X), as they operate on one row of cells at a time.
The main ones are are development, configuration and readback.

Closest to Støvnengs CA in 2D:
[rules tested in parallel] = 2.
[lut configuration bits] = 2.

Speed differences:
1/4x config.

Closest to Støvnengs CA in 3D:
[rules tested in parallel] = 2.
[lut configuration bits] = 8.

Speed differences:
4x rsf/live counter.
1/2x config.
1/8x readback.


\todo{best performance}

\subsection{Communication}

\TODO
\tablename~\ref{tab:communication-performance}.

\begin{table}[!ht]
    \renewcommand{\arraystretch}{1.4}
    \centering
    \begin{tabular}{c|c|c}
        \bfseries Mode & \bfseries Latency & \bfseries Throughput \\
        \hline
        Normal & \SI{60.3}{\micro\second} & 2.1 MB/s \\
        Low-latency & \SI{7.3}{\micro\second} & 2.1 MB/s \\
    \end{tabular}
    \caption[Communication performance]{
        Performance of the PCI Express communication unit.
    }
    \label{tab:communication-performance}
\end{table}

\TODO
Likely due to minimum system sleep of around \SI{50}{\micro\second}.

The throughput is not exceptional at around 1\% of the 256MB/s that the PCI Express endpoint block is capable of \cite{ug672}.
This is likely due to the simplistic PIO scheme that require that all transfers go through the CPU.
However, this is not as bad as one would first assume.
Following is a short analysis of the desired throughput for the example program in \figurename~\ref{fig:example-program}.

\begin{figure}[!ht]
\begin{lstlisting}[xleftmargin=0.35\textwidth]
initialize()
while counter[0] != 128:
    develop()
    config()
    step(128)
    send_fitness()
    swap_cell_storage()
    counter[0]++
\end{lstlisting}
\caption[Example program] {
    Example program.
}
\label{fig:example-program}
\end{figure}

Assume the following synthesis parameters:
[LUT Configuration Bits] maximized to 8,
[Rules Tested In Parallel] set to 8,
[Rule Amount] set to 256,
[Fitness] set to DFT with transform size of 128 and 16-bit output values,
and the matrix sized to 10x10x8.

That brings development speed to 3.2 cycles/cell and configuration speed to 1.6 cycles/cell (plus overhead)\footnotemark.
The DFT work in parallel with the rest of the design, therefore adding no further delay, and produces 32 words of data after each 128 steps.
With 800 cells, the time for each loop iteration then becomes a little over $3.2 \cdot 800 + 1.6 \cdot 800 + 128 = 3968$ cycles.
32 words per 3968 cycles at 125 Mhz constitutes around 4 MB/s.
The communication unit can therefore supply 50\% of the desired throughput, which should be acceptable for normal operation.

\footnotetext{
    The execution time of each instruction is detailed in Appendix~\ref{app:isa}.
}

%==============================================================================%

\section{Challenges}
\label{sec:challenges}

\TODO

ISE lacks support for VHDL-2008, which is required to use custom types with generics.
All array signals must therefore be converted to and from std\_logic\_vectors before exiting and after entering modules.
Hopefully, this is implemented in a way that is organized and understandable.

\TODO

%==============================================================================%

\section{Future work}

\TODO

Further parameterization:
Could parameterize number of rows accessed in Cell Storage to allow higher config and readback speeds.
Make Live Counter easily replaceable (step function module)(like fitness module, improves flexibility), and allow it to use more cycles (reduces LUT usage).
Also live counter to use more cycles but reduce LUT usage.

However, LUT and register usage are not issues for 3D; routing and available shift registers are.
Shift registers set max number of cells.
Routing limits livecounter + rule testers.
In 2D, LUTs and like routing are the major issues.

\begin{itemize}
    \item Hazard detection unit so multiple modules can run simultaneously
    \item DMA-based communication interface (better speed, requires driver, more advanced com module, programs don't need sudo)
    \item Watchdog-timer/Stall-prevention
    \item Introduce two clock domains again to double performance
\end{itemize}

%==============================================================================%

\section{Warnings}

\begin{itemize}
    \item Most are due to parameterization
    \item Many from generated PCIE core
    \item Nearly all filtered to make output more readable and make it easier to find bugs
    \item Could not remove remaining due to limited filter system (don't want to cause trouble later)
    \item 728 in ISE (684 filtered)
    \item 502 in XST (457 filtered)
    \item (3D)
    \item Why the difference?
    \item Also filtered "equivalent register removal" infos to reduce clutter
\end{itemize}
