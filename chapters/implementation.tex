\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{implementation-simple}
    \caption[High-level system diagram]{High-level block diagram of the new hardware platform.}
    \label{fig:implementation-simple}
\end{figure}

\begin{sidewaysfigure}[!pt]
    \centering
    \includegraphics[width=\textwidth]{implementation-full}
    \caption[Detailed system diagram]{
        Detailed block diagram of the new hardware platform.
        Control is implemented as a group of modules, marked by a dotted border.
        Some signals are color-coded for increased readability.
        Signals from Decode are colored red, while those to the Send Buffer and Cell Storage Multiplexers are colored blue and purple respectively.
        Note the two different hues of purple for the different Cell BRAMs.
        Control signals are not shown.
    }
    \label{fig:implementation-full}
\end{sidewaysfigure}

The platform is design as an interlocked pipeline.
The main stages are Fetch, Decode and Execute, but due to interlocking, each stage can contain sub-pipelines or state machines.

The Execute stage is special in that is is split into many sub-modules, where only one is activated at a time.
The exception is Fitness, which is always active, since it operates in a dataflow-like fashion.
A hazard detection unit could be implemented to increase performance by allowing multiple non-conflicting units run in parallell.

Interlocking is implmented using special Run and Done signals.
Run is asserted when all modules asserts Done.

All state machines are of Mealy design with clocked output, unless noted otherwise.

\todo{Rewrite this!}

%==============================================================================%

\section{General Consepts}

\todo{Control signals not shown, only data}
\todo{Borders: Green = BRAM, grey = outside}
\todo{BRAM vs Buffer. Move buffer description here?}

\subsection{Parameterization}

\begin{itemize}
    \item Used pretty much everywhere
    \item Most can be 1 to inf
    \item Asserts where restrictions apply
    \item List them all?
\end{itemize}

\subsection{Pipelining}

The new hardware design makes extensive use of pipelining, and since many stages use a variable amount of cycles for a variety of reasons \todo{which? state machine, pipeline in pipeline, simpler}, interlocking is used in nearly all pipelines.
Interlocking is implemented with two signals connected to each stage: Run and Done.
When a stage does not require further cycles to finish, it asserts its Done signal and then waits for the Run signal before continuing.
The Run signals for all stages are asserted when all Done signals are asserted.
Each stage then resets its Done signal and the process repeats.
An example is shown in \figurename~\ref{fig:wavediagram-pipeline}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\textwidth]{wavediagram-pipeline}
    \caption[Pipeline wave diagram]{
        Wave diagram showing pipeline interlocking signals for a 3-stage pipeline where the stages complete in one, two and three cycles respectively.
    }
    \label{fig:wavediagram-pipeline}
\end{figure}

Often, a multi-cycle stage only looks at its input in the first cycle to determine its execution path.
This can be taken advantage of to reduce register usage by ruling that the data in the pipeline registers only have to be valid when Run is asserted.
The stages can then write directly to their output registers, instead of caching partial output internally in extra registers.
If a stage happens to require the output of the previous stage for multiple cycles however, input caching is needed.
This causes no register usage reduction in the worst case, while the register usage is halved in the best case.
The common case for this design is to only look at the input the first cycle for most signals, which should provide a nice reduction.

\subsection{Buffers}

All buffers are implemented as first-in first-out (FIFO) queues using block RAM (BRAM) and two counters.
The counters determine the addresses that are written to and read from, and are incremented when the write or read signals are asserted.
\figurename~\ref{fig:wavediagram-fifo} shows how the FIFO is used to buffer two words.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/wavediagram-fifo}
    \caption[FIFO buffer wave diagram]{
        Wave diagram for the FIFO buffer, showing two consecutive writes followed by two consecutive reads.
    }
    \label{fig:wavediagram-fifo}
\end{figure}

Notice how the read signal needs to be asserted before the clock tick when data is read to ensure correct consecutive reads.
This is due to the BRAM used in the FIFO, which updates at clock ticks.
To have correct data available for a read in the following cycle, the address therefore has to be updated before the clock tick (by asserting the read signal).

%==============================================================================%

\section{Communication}

The new communication unit is based on Xilinx' reference PCI Express programmed input/output design.
It consists of the Xilinx PCI Express endpoint core, reception and transmission engines, data buffers, and a special request handler, as shown in \figurename~\ref{fig:implementation-communication}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{implementation-communication}
    \caption[Communication module]{
        Detailed block diagram of the communication module.
    }
    \label{fig:implementation-communication}
\end{figure}

The endpoint core completely handles the physical and data link layers, and all TLPs related to configuration and establishment of the PCI Express connection.
The reception engine is responsible for parsing TLPs and either writing received data to the reception buffer or notifying the transmission engine about a read request.
The transmission engine is responsible for building completer TLPs to respond to read requests, using data from the transmission buffer.
The request handler listens to the read requests provided by the reception engine, and can override the transmission engine to respond to special requests.

\subsection{PCI Express Endpoint Core}

Several Spartan-6 FPGAs, including the one used in this project, contain a special-purpose hardware block for implementation of PCI Express.
The block completely handles the physical and data link layers, with the transaction layer left for the user.

To make use of the block, Xilinx provides the Spartan-6 Integrated PCI Express Endpoint Core; version 2.3 was used in this project.
This core additionally takes care of all TLPs related to configuration of the PCI Express connection.
Other TLPs, such as read and write requests, are presented on an AXI4-Stream interface \cite{ug672}.

The endpoint core is configured with two memory regions, both 4 kB in size\footnotemark.
\footnotetext{
    The smallest memory region that can be memory-mapped is one page. The default page size in Linux is 4 kB.
}
The first memory region (BAR0) is used for normal communication, while the second (BAR1) is used for special requests.
The separation is mostly conseptual as both regions are treated as one data stream.
The difference is that the special request handler kicks in for read requests to BAR1.

\subsection{Reception engine}

The reception engine is implemented as a simple state machine, as shown in \figurename~\ref{fig:statemachine-receive}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{statemachine-receive}
    \caption[Reception engine state machine]{
        State machine for the reception engine.
    }
    \label{fig:statemachine-receive}
\end{figure}

Until the endpoint core presents valid data, the state machine remains in Idle.
When it does, the data is stored, and the TLP type is checked.
If it is a read or write request, the state machine continues down the corresponding path, otherwise the remaining data is discarded.
The remaining portion of the TLP headers are then parsed in the DW1 and DW2 states.
For read requests, the state machine waits in ReadWait until the transmission engine is ready to accept a new read request, and then proceeds to Idle.
For write requests, the state machine stays in WriteData, where one DW of data is written to the reception buffer each cycle, for the length of the packet, and then proceeds to Idle.

\subsection{Transmission engine}

The transmission engine is implemented as a simple state machine, as shown in \figurename~\ref{fig:statemachine-transmit}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{statemachine-transmit}
    \caption[Transmission engine state machine]{
        State machine for the transmission engine.
    }
    \label{fig:statemachine-transmit}
\end{figure}

Until the reception engine signals a read request, the state machine remains in Idle.
When a read request is signaled by the reception engine, the state machine begins to traverse the DW path.
The DW0, DW1 and DW2 states each transmit one DW of the completer TLP header.
Then if the special request signal is set, it procceds to CompleteSpecial, where it transmits data presented by the request handler.
Otherwise, it proceeds to CompleteData where it transmits one DW of data from the transmission buffer each cycle.
When the requested number of DWs has been transmitted it proceeds back to Idle.

\subsection{Request handler}

The request handler continually listens to the read requests presented by the reception engine.
If the request is targeting the primary memory area (BAR 0), it is a normal read request and the transmission engine is allowed to proceed as usual.
Otherwise, it is a special request and the transmission engine is overridden.

The kind of special request is determined by the address of the read request, and handled thereafter.
There are currently four special requests implemented, as shown in Table~\ref{tab:requests}.

\begin{table}[!ht]
    \renewcommand{\arraystretch}{1.3}
    \centering
    \begin{tabular}{c|l}
        \bfseries Address & \bfseries Request \\
        \hline
        0x00 & Get transmission buffer data count \\
        0x01 & Get transmission buffer available space \\
        0x02 & Get reception buffer data count \\
        0x03 & Get reception buffer available space \\
    \end{tabular}
    \caption{Special requests.}
    \label{tab:requests}
\end{table}

Note that each of the implemented special requests assumes a read request length of one DW.
If the request has a greater length, the returned data is simply repeated to fill the packet.

%==============================================================================%

\section{Fetch}

The Fetch module is responsible for retrieving the next instruction that should be decoded and then executed.
It also handles all control flow.
It is implemented as a two-stage interlocked pipeline consisting of a Fetch Communication module and a Fetch Handler module connected to an Instruction BRAM.
This is shown in \figurename~\ref{fig:implementation-fetch}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{implementation-fetch}
    \caption[Fetch module]{Detailed block diagram of the Fetch module.}
    \label{fig:implementation-fetch}
\end{figure}

Fetch Communication is responsible for converting data from the communication module into instructions while the Fetch Handler handles \todo{something that cover all operations}.
Both stages are implemented as state machines, making interlocking necessary.

\subsection{Fetch Communication}

While instructions are 256-bit, the communication interface is only 32-bit.
This means that the host system has to split each instruction into multiple 32-bit pieces.
As detailed in Appendix \todo{add ISA}, many instructions make use of less than 256 bits.
In fact, most instructions fit within the first 32 bits.
Sending all 256 bits for each instruction is therefore a bit excessive.
To optimize communication, the first 32-bit piece of each instruction has a field declaring the amount of following pieces required for reassembly.

The job of the Fetch Communication module is to combine all the pieces back into full 256-bit instructions.
It starts by reading the first 32-bit piece and setting all other bits to zero.
Then, the 3-bit instruction length field is analysed to determine how many further pieces are part of the same instruction.
The remaining pieces are then incorporated into the instruction, before it is passed on to the Fetch Handler.

\subsection{Fetch Handler}

The Fetch Handler has three modes of operation: FetchCom, FetchMem and StoreMem.
The modes and transitions are implemented as a state machine, which is shown in \figurename~\ref{fig:statemachine-fetch-handler}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.6\textwidth]{statemachine-fetch-handler}
    \caption[Fetch Handler state machine]{State machine for the Fetch Handler.}
    \label{fig:statemachine-fetch-handler}
\end{figure}

In FetchCom mode, instructions are fetched from communication and sent to decode.
Since a variable-length format is used, this may take multiple cycles.
To make sure that instructions does not get "stuck" in the pipeline due to no further instructions arriving at the communication interface, NOPs are sent when Fetch Communication is busy.
When encountering a Store instruction, it enters StoreMem mode and for a Jump instructions it enters FetchMem mode.

In FetchMem mode, instructions are fetched from InstructionBRAM and sent to decode.
The first InstructionBRAM address is specified by the Jump instruction, and then it is incremented by one after each instruction.
When encountering a Break instruction, it enters FetchCom mode.

In StoreMem mode, instructions are fetched from communication and stored in InstructionBRAM.
The first InstructionBRAM address is specified by the Store instruction, and then it is incremented by one after each instruction.
Instructions are stored in full 256-bit format.
When encountering an End instruction, it enters FetchCom mode.

Control flow is implemented by having N M-bit general counters and a JumpEqual instruction.
The counters can be incremented or reset using special instructions.
The JumpEqual instruction is treated as a Jump instruction when the specified counter matches the specified value, otherwise it is discarded.

%==============================================================================%

\section{Decode}

Decode is responsible for parsing instructions, setting up control signals and passing instruction parameters to activated modules.
It is a very simple module, being essentially a giant switch statement with a case for each instruction.

Control signals are sent to all toplevel modules except communication, fetch and fitness.
\todo{why not fitness? dataflow-like}
By default, all modules are given a no-operation signal and multiplexers stay unchanged.
Then, depending on the instruction's operation code, the control signal for the appropriate module is set, parameters (if any) are extracted and passed on, and multiplexers are changed if needed.

Each operation code corresponds to exactly one control signal for one module.
Instructions can only activate one module.
\todo{buffer reset}
\todo{active rules}

Control signals for every top-level module except for communication, fetch and fitness.
Selects one module that should be run and sends instruction parameters to it.

The control signals determine which module is activated, which modules the CellBufferMux and SendBufferMux will connect to, and if the CellBuffer should swap contents.

\todo{This is all jumbled... REWRITE!}

%==============================================================================%

\section{Control}

Control is a group of modules, shown in \figurename~\ref{fig:implementation-control}.
Together, the modules control all inputs and outputs for the Cell Storage, Cellular Automaton and Development modules.
Each module is designed to do one spesific task and be independent of any other modules.
This means that modules are mostly very simple and that it requires a low amount of effort to add new modules or to modify existing.
\todo{tie in UNIX principles somehow?}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{implementation-control}
    \caption[Control modules]{
        Detailed block diagram of the Control modules.
        Red signals are inputs while blue are outputs.
        Control signals are not shown.
    }
    \label{fig:implementation-control}
\end{figure}

Below are details about the different modules, in order of increasing complexity.
\todo{rewrite/remove this?}
\todo{send to system = put into transmission buffer}
\todo{possible to create deadlocks due to waiting}

\subsection{Rule Writer}

The purpose of the Rule Writer is to store new rules to the Rule BRAM within the Development module.
It is, along with the LUT Writer, the simplest control module.
When activated, it stores one rule to a specified index of the Rule BRAM.
The index doubles as priority for a rule, with higher indexes having higher priority.

As explained in Section~\ref{sec:development}, index zero is reserved for representing that no rules have triggered.
Writing a rule to it has no effect as the rule testers are reset instead of testing the rule during development.

\subsection{LUT Writer}

The purpose of the LUT Writer is to store new LUTs to the LUT BRAM within the Cellular Automaton module.
It is, along with the Rule Writer, the simplest control module.
When activated, it stores one LUT to a specified index of the LUT BRAM.
The index signifies the cell type that should be converted into the LUT.
\todo{clarify}

\subsection{Information Sender}

Nearly all parts of the system are parameterized.
The previous practice of manually ensuring that the parameters of both the design and API were in sync was both tiresome and prone to error.
Therefore, the Information Sender provides a means for the API to automaticly query these parameters.

When activated, it puts all parameters that might be useful into the the Transmission Buffer.
This includes information about the CA such as the size, whether wrapping is enabled, and number of bits per state and type;
information about counters available for control flow;
maximum number of rules;
and information about the fitness modules, such as the type and output size.

\subsection{Fitness Sender}

The Fitness Sender is responsible for sending the output of the Fitness module to the host.
As this is data is stored in the Fitness Buffer, is is a simple matter of moving it to the Transmission Buffer when the data is available and the buffer is ready.
As described in Section~\ref{sec:fitness}, the Fitness module declares how many words should be sent per output value.
This is taken into account by the Fitness Sender when activated.
\todo{do something with last sentence}

\subsection{Rule Vector Reader}

The Rule Vector Reader is tasked with reading the rule vectors created by the Development module and sending them to the host.
Multiple rule vectors can be read with one instruction.
Since rule vectors can be of any length, they are each split over multiple words, starting with the lowest indexes.
The final word of each vector is padded with zeroes.
\todo{this sentence is a bit off}
For more information on rule vectors, see Section~\ref{sec:development}.

\subsection{Rule Numbers Reader}
\label{sec:rule-numbers-reader}

The Rule Numbers Reader is tasked with reading each cell's most recently activated development rule and sending them to the host.
The rule numbers are stored in the Rule Numbers BRAM of the Development module and are scanned in raster order\footnotemark.
\footnotetext{
    In raster scanning, two-dimensional data is read line-by-line, least significant to most significant.
    This is extendable to 3D; first X is incremented, then Y, then Z.
    \todo{better explanation}
}

Each word is fitted with as many rule numbers as possible without splitting them over multiple words or containing ones from different rows.
Any remaining space is filled with zeroes.
\todo{more details?}

\subsection{Cell Writer Reader}

The purpose of the Cell Writer Reader is to perform read and write operations against Cell BRAM A, causing it to be the system's main input/output channel.
It is possible to write states and types to either a single cell, a row of cells or the entire BRAM, while it it is possible to read from a single cell or the entire BRAM.

It is easily the most complex control module, due to the intricate operations required to change only selected values in BRAM rows.
Additionally, it must convert variable-width types and states into fixed-width words in an efficient manner when reading.

The module consists of combiners which are used to combine new data with existing data from the Cell BRAM, repeaters to simplify the process of filling the entire Cell BRAM with a given state and type, shifters used to select output, and a state machine which controls everything.
\figurename~\ref{fig:implementation-cell-writer-reader} shows how the components are connected.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{implementation-cell-writer-reader}
    \caption[Cell Writer Reader]{
        Detailed block diagram of the Cell Writer Reader.
        Only the state part is shown to reduce complexity; the type part is identical.
        Cell BRAM A is drawn inside the module for completeness.
        Control signals are not shown.
    }
    \label{fig:implementation-cell-writer-reader}
\end{figure}

\subsubsection{Combiner}

The combiner is a combinatorial unit that combines two signals of different lengths by replacing one part of the long signal with the short signal.
This is implemented using a shifter and a mask that is the size of the short signal.
First, the short input and mask is shifted into the desired position.
Then, the long signal is anded with the inverted mask and ored with the short signal, producing the combined signal.
The process is illustrated in \figurename~\ref{fig:combiner}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{combiner}
    \caption[Combiner operation]{
        The three operations that power the combiner.
        A is the short input, highlighted in green.
        B is the long input, highlighted in orange.
        The mask is highlighted in yellow.
    }
    \label{fig:combiner}
\end{figure}

\subsubsection{State Machine}

The state machine consists of seven states, shown in \figurename~\ref{fig:statemachine-cell-writer-reader}.
When an operation is received, the BRAM address is set and it transitions from idle to the corresponding state.
Some states are dual-purpose due to the similarity of the operations, while others are not.
Coincidentally, the dual-purpose states complete in one cycle while the others require multiple\footnotemark.
\footnotetext{
    Techically, the Send One state does not necessarily complete in one cycle since it will wait until there is available space in the Transmission Buffer.
    However, it is the common case.
}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.55\textwidth]{statemachine-cell-writer-reader}
    \caption{Cell Writer Reader state machine}
    \label{fig:statemachine-cell-writer-reader}
\end{figure}

The dual-purpose states are as follows:
Send One can send either a state or a type, Write State can write either one or a row of states, and Write Type can write either one or a row of types.
The remaining states are:
Fill writes the same state and type to all cells, Send All States reads all states in raster order, and Send All Types reads all types in raster order.
The output formatting of the Send All states is equal to that of the Rule Numbers Reader, detailed in Section~\ref{sec:rule-numbers-reader}.

%==============================================================================%

\section{Cell Storage}

The Cell Storage serves as the location for exchange of cell data between the CA, Development and Host.
It contains two separate storage areas, the contents of which can be swapped.
Each storage area can host a full matrix of cell states and types, and allows one row of each to be read each cycle.
The main reason two storage areas are needed is the Development module.
It requires a place to store its output without affecting its input during the development process.
More on this in Section~\ref{sec:development}.

The module is implemented as two dual-port BRAMs, one for states and one for types, each sized to twice the size of the matrix.
To create two separate storage areas (A and B) with both states and types, the address of the first port is prefixed with 0 and the second with 1.
The contents of the storage areas can then be made to appear swapped by simply inverting the prefix bits.

To service all required components, the Cell Storage is connected via a multiplexer.
It has two modes; normal and development.
In normal mode, storage A is connected to the Cell Writer Reader and storage B to the CA.
In development mode, both storage areas are connected to the Development module.

\todo{fig?}

%==============================================================================%

\section{Development}
\label{sec:development}

The Development Module is responsible for providing the ontogenic aspect of the system by allowing cells to be changed based on user-supplied development rules.
It uses Cell Storage A as input and outputs the modified cells to Cell Storage B.

The module is implemented as a two-stage interlocked pipeline controlled by a state machine.
Stage one contains the Cell Fetcher, which retrieves cell neighborhoods from Cell BRAM A, and stage two contains a four-stage pipeline that tests development rules against the cell neighborhoods.
This is illustrated in \figurename~\ref{fig:implementation-development}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{implementation-development}
    \caption[Development module]{
        Detailed block diagram of the Development module.
        The two main pipeline stages are separated by a dashed line,
        while the substages of the pipeline within the second main stage are marked at the top.
        The cell BRAMs are drawn inside the module for pipeline completeness.
        Control signals are not shown.
    }
    \label{fig:implementation-development}
\end{figure}

The state machine, shown in \figurename~\ref{fig:statemachine-development}, ensures proper timing of the complex pipeline.
It is responsible for setting input and output addresses, activating pipeline stages and setting write signals.
A complete timing diagram can be seen in \figurename~\ref{fig:wavediagram-development}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.75\textwidth]{statemachine-development}
    \caption[Development module state machine]{
        State machine controlling the Development module.
    }
    \label{fig:statemachine-development}
\end{figure}

\begin{sidewaysfigure}[!pt]
    \centering
    \includegraphics[width=\textwidth]{wavediagram-development}
    \caption[Development module wave diagram]{
        Wave diagram for the Development module, showing the development process for an Nx2 matrix with five active rules.
    }
    \label{fig:wavediagram-development}
\end{sidewaysfigure}

\subsection{Cell Fetcher}

The Cell Fetch reads the cell neighborhoods for one row of cells from Cell BRAM A per run.
It is implemented as two state machines, one which sets the BRAM address and one which retrieves the output.
The first can be seen in \figurename~\ref{fig:statemachine-cell-fetcher}.
The other is equivalent to the first except for being delayed two states, thus having Wait 1 as initial state instead of Fetch Center.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{statemachine-cell-fetcher}
    \caption[Cell Fetcher state machine]{
        State machine for the Cell Fetcher.
    }
    \label{fig:statemachine-cell-fetcher}
\end{figure}

By reading an entire row at a time, the neighbors along the X axis are fetched "for free" due to wrap-around, while the other axes require two extra reads each.
This lands the runtime on 5 cycles for 2D matrices and 7 cycles for 3D, including BRAM latency.
\todo{remove/change quotes?}
\todo{CellFetch limiting factor for very few rules}

\subsection{Rule Fetcher}

The Rule Fetcher is responsible for fetching development rules from Rule BRAM and passing them to the Rule Testers.
It takes into account the specified number of active rules to speed up the development process by only fetching those.
It is possible to further improve performance by setting that multiple rules should be fetched and tested at the same time.
In that case, those with indexes higher than the number of active rules within the last rule batch are replaced by rules with no effect.

\subsection{Rule Testers}

The Rule Testers are responsible for testing development rules received from the Rule Fetcher against cell neighborhoods received from the Cell Fetcher.
They are unique in that they produce output after both one and two cycles.
Information about rule activations, "hits", are passed on to hit processors after one cycle and the result of the rule application is passed on to Cell BRAM B after two cycles.

There is a special case for rule zero.
It is used as an internal reset by forcing a hit and setting the output cell to the input cell.
This implementation was chosen because of its simplicity and ability to use zero to mean "unchanged" in hit processors.
It also makes it possible to have no active rules.

\subsection{Hit Processors}

There are two modules dedicated to providing information about the development procedure, Hits To Vector and Hits To Numbers.
The input for both are hits passed on from the Rule Testers.

Hits To Vector stores a vector where each bit signifies whether the rule of that index was triggered or not to the Rule Vector Buffer each devstep.
\todo{explain devstep or find another term}
Rules that have triggered but is later overridden by a rule with higher priority is still marked as having been triggered in the vector.
If the buffer is full, it is reset instead of waiting, to allow programs to disregard the data without causing deadlocks.

Hits To Numbers stores the index of the last triggered rule for each cell to the Rule Numbers BRAM.
Since rule zero is always marked as a hit, the BRAM is cleared each devstep before the actual rule numbers are written.
\todo{explain devstep or find another term}

%==============================================================================%

\section{Cellular Automata}

The Cellular Automata module is the centerpiece of the system.
It is what contains the sblock matrix and the control logic to service it.
The module is responsible for configuring the sblock matrix with data from Cell BRAM B, step the sblocks and store the number of live cells afterwards, and write the new states back to Cell BRAM B.

The implementation can be seen in \figurename~\ref{fig:implementation-cellular-automata}.
It consists of a state machine, the Sblock Matrix and a Live Counter, in addition to storage for LUTs and a buffer for the Live Counter.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{implementation-cellular-automata}
    \caption[Cellular Automata]{
        Detailed block diagram of the Cellular Automata.
        Config Readback is a symbolic module for majority of the state machine.
    }
    \label{fig:implementation-cellular-automata}
\end{figure}

\subsection{State Machine}

The state machine in \figurename~\ref{fig:statemachine-cellular-automata} is what powers this module.
It is what controls both configuration, readback and stepping of the Sblock Matrix.
Additionally, it sets write signals for the Live Count buffer.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{statemachine-cellular-automata}
    \caption[Cellular Automata state machine]{
        State machine controlling the Cellular Automata.
    }
    \label{fig:statemachine-cellular-automata}
\end{figure}

Configuration is the process of taking cells from Cell BRAM B, converting them into LUTs and programming the sblocks.
It operates on one row of cells/sblocks at a time.
First, the cells are read from Cell BRAM B and the type of each are used as addresses for the 1-in N-out LUT BRAM to find the corresponding LUT.
The LUTs are then loaded into shift registers and transfered to the sblocks piece by piece.
Finally, the outputs of the sblocks are set to the states of the cells.

Readback is the process of extracting the cell states from the Sblock Matrix and storing them back in Cell BRAM B.
This operation also works on one row at a time.
However, it is much simpler and faster than configuration since it simply directs the output of the sblocks to the Cell BRAM and sets the correct row.

Stepping is simply the process of telling the Sblock Matrix to update all of its sblocks.
Since it is common to step hundreds of times in a row, the step instruction has a parameter for the number of steps, up to a maximum of 65535 (a 16-bit number).

\subsection{Sblock Matrix}

The Sblock Matrix essentially contains enormous amounts of sblock as they are described in Section~\ref{sec:sblock}.
The only difference is that the sblocks used here have support for configuring multiple bits of the LUT each cycle.
However, to use the dedicated shift registers as configurable LUTs, there are some restrictions on the number of bits.
Firstly, it can only be powers of two; secondly, it can be maximum 2 for 2D matrices and 8 for 3D.
Keep in mind that each bit adds one extra signal for each sblock, which accumulates to a significant amount of routing resources.

By default, neighbors which would be outside the matrix are treated as having zero for both state and type.
However, it is possible to enable matrix wrapping to instead use the neighbors on the opposite side of the matrix.
Having this option lets the user decide if programs should be able to exploit the matrix size to create oscillators or not.
\todo{also applies to devstep}

\subsection{Live Counter}

The Live Counter is essentially a giant adder tree that is connected to the output of each sblock.
It calculates the total number of live cells after each runstep and stores them in the Live Count Buffer.
\todo{explain runstep or use other term}
Due to the massive amount of sblocks, the calculation is spread out over many cycles, the exact number of which is dependant on the number of sblocks.
However, the throughput remains at one total per cycle.

If the Live Count Buffer happens to be full, it is reset instead of waiting, to allow programs to disregard the data without causing deadlocks.
This will likely corrupt all fitness evaluation until the buffers are reset however.

%==============================================================================%

\section{Fitness}
\label{sec:fitness}

The Fitness module is responsible for evaluating the output of the CA for use with evolutionary algorithms.
Since fitness evaluation vary widely between applications, the interface of the Fitness module is designed to be simple and generic, such that the module is easy to replace.

It is connected in a dataflow-like manner between the Live Count Buffer and the Fitness Buffer.
Whenever there is enough data available in the Live Count Buffer, it should fetch that data, processes it, and store the result to the Fitness Buffer.
The host can then later retrieve it by activating the Fitness Sender.

To comply with the adaptive interface, there are a few things that the Fitness module needs to tell the other parts of the system.
First is the number of words per result, required by the Fitness Sender.
Second is a unique identifier that is reported to the host by the Information Sender.
To allow further versatility, the module can also report synthesis parameters to the host.

There are currently two implemented fitness modules: Live Count and DFT.

\subsection{Live Count}

The Live Count fitness module is used to transfer the live counts to the host for software-side fitness evaluation.
The implementation is as simple as it gets.
The output of the Live Count Buffer is fed directly into the Fitness buffer, and the write and read signals are activated when the Live Count Buffer has data and the Fitness Buffer has space.

\subsection{DFT}

The DFT fitness module uses a Discrete Fourier Transform to convert the the live count data into frequency spectrums.
This has the advantage of being able to pick up certain information that might be near-impossible to detect using conventional means.
As shown in \todo{ref}, using a DFT to interpret CA output holds potential.

A DFT of transform size N takes N complex numbers as input and produces N complex numbers as output.
For transforms where input numbers are all real, the second half of the output mirrors the first half and can be safely ingored to save computation effort.
Each output value of the DFT is a linear combination of all input values.
The constants, which are known as twiddle factors, rely only on the transform size and can therefore be computed ahead of time to reduce the complexity of the calculations.
\todo{a bit funky}
\CN

This module is essentially a revised version of Støvneng's design in \cite{stovneng2014sblock}.
It has been refactored, streamlined and adapted to fit into the new design.
It is also more customizable, supporting parameters other than powers of two, and can generate twiddle factors by itself during synthesis instead of relying on an external program.

To allow the DFT to continue processing while results are transferred from the DFT to the Fitness Buffer, the module is divided into two pipeline stages.
This can be seen in \figurename~\ref{fig:implementation-dft}.
The first stage contains the DFT while the second contains the logic for transferring the result.
The pipeline is interlocked, since both stages can run for hundreds of cycles, and is controlled by the statemachine in \todo{fig}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{implementation-dft}
    \caption[DFT Fitness]{
        Detailed block diagram of the DFT Fitness module.
        The two pipeline stages are marked at the bottom.
        Blue boxes are multiplexers.
        Control signals are not shown.
    }
    \label{fig:implementation-dft}
\end{figure}

The DFT is calculated using the DSP slice wrappers seen in \figurename~\ref{fig:implementation-dsp} in multiply-accumulate mode.
Afterwards, the real and imaginary parts of each output value are combined into a single positive number by adding the absolute value of both.
The most optimal configuration would be two DSP slices per output value, one for each real and imaginary part.
However, FPGAs have a limited number of DSP slices.
For larger transform sizes, the DSPs therefore have to calculate multiple output values in sequence.
Since the Live Count Buffer, as all FIFO buffers, is delete-on-read, an internal buffer is used to repeat the values.
This Repeat Buffer is flushed and filled during the first run and then repeats the values to the DSPs during subsequent runs while also feeding the values back into itself.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]{implementation-dsp}
    \caption[DSP Wrapper]{
        Detailed block diagram of the DSP Wrapper.
        Red boxes are registers and blue boxes are multiplexers.
    }
    \label{fig:implementation-dsp}
\end{figure}

%==============================================================================%

\section{Software API}

\TODO
Full rewrite
Adaptive x9001.
Full system reset.
Queries synthesis parameters at connect.
PCI -> Com -> CARP.
Compiled to staticly linked library (libcarp.a).
Just dump files in programs and run make.
Export to postscript (hex codes to color).
Functions return data structures (can be printed).
Testbench mode: Mocks info struct, exits on flush.
Debug mode: Prints all com data.
Low latency mode: No sleep between buffer checks.

\subsection{Communication}

The communication part of the new software API is split into two parts:
\todo{this lone sentence is kinda awkward}

The first is a general interface for connecting to PCI and PCI Express devices without using a custom driver.
It takes advantage of Linux' automatic population of /sys/devices/pci* with files representing the memory regions of all PCI and PCI Express devices.
The directory is searched by vendor and device id, and the corresponding memory regions is memory-mapped into the program.

The second is an interface specifically for the communication unit.
It provides open, close, read and write functions similar to the old BenERA interface, in addition to implementing all special request functions in Table~\ref{tab:requests}.
When a read or write operation is initiated, buffers are checked for available data or space.
If there is not enough present, the program waits and then rechecks.

